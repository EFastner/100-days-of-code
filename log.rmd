---
title: "100 Days of Code Tracking Log"
author: "Eric Fastner"
date: "January 1, 2019"
output:
  pdf_document: default
  html_document: default
---  


###_Template_  

### Day 0: January 1, 2019

**Time:**

**Today's Progress:**

**Thoughts:**

**Link to work:** 

***********

# 100 Days Of Code - Log

### Day 1: January 1, 2019

**Time:** 120 Minutes (8:30 PM - 10:30 PM)

**Today's Progress:** Forked and Modified the 100 Days of Code resources to fit my needs. Split my previous Lock Line Analysis into it's own repository via [this page](https://help.github.com/articles/splitting-a-subfolder-out-into-a-new-repository/)

**Thoughts:** Lots of misc items completed that I've been putting off for awhile, I almost pushed the start of this until tomorrow. Ultimately, it was still a really positive 2 hours! 

**Link to work:** [New Lock Line Analysis Repo](https://github.com/EFastner/Lock_Line_Analysis), [100 Days of Code Repo](https://github.com/EFastner/100-days-of-code)

### Day 2: January 2, 2019

**Time:** 120 Minutes (10:00 PM - 12:00 AM)

**Today's Progress:** Converted lock line vizualization script into a function, branched the file via [these instructions](https://git-scm.com/book/en/v2/Git-Branching-Basic-Branching-and-Merging), and re-merged with the master branch

**Thoughts:** I need to get more comfortable with branching, but we'll get there. The foundations for this function may be fun to ultimately load into some sort of Shiny app. The code is becoming a lot more flexible

**Link to work:** [New Lock Line Viz Function](https://github.com/EFastner/Lock_Line_Analysis/blob/master/lock_line_viz.R)

### Day 3: January 3, 2019

**Time:** 90 Minutes (8:15 PM - 9:45 PM)

**Today's Progress:** Experimented with the RPostgreSQL package in R to learn how to interact with PostgreSQL. Utilized an [r-bloggers](https://www.r-bloggers.com/getting-started-with-postgresql-in-r/) tutorial to get started. 

**Thoughts:** This was a big confidence boost. I've been a little intimidated about getting this set up, but it was WAY easier than I thought it would be. Glad I have this challenge to make me sit down and figure some of this out

**Link to work:** [New RPostgreSQL Functions](https://github.com/EFastner/RPostgreSQL_Functions)

### Day 4: January 4, 2019

**Time:** 60 Minutes (7:30 PM - 8:30 PM)

**Today's Progress:** Kind of a light day. Didn't get a lot done. Played around with the RPostgreSQL commands to begin creating and populating tables via RStudio

**Thoughts:** Mostly exploratory, should come in handy for Day 5

**Link to work:** [New RPostgreSQL Functions](https://github.com/EFastner/RPostgreSQL_Functions)

### Day 5: January 5, 2019

**Time:** >150 Minutes (Off and on from 10 AM - 4:00 PM)

**Today's Progress:** Created and populated tables with game results by season from 2007 - 2018, a table with the same data organized by team, and a table with each individual skater's stats going back to 2007. Updated some old summary functions as well

**Thoughts:** Lots of work to do! I need to stop reusing the table creation and populating functions for specific tables. Either I need to make them more flexible, or I need to start creating separate functions for each new table. The game summary and skater summary functions could also use some extra documentation/streamlining. Maybe this would be a good time to start inplementing some unit testing? 

**Link to work:** [New RPostgreSQL Functions](https://github.com/EFastner/RPostgreSQL_Functions), [Skater Summary](https://github.com/EFastner/PbP_Analysis/tree/master/PBP_Functions)

### Day 6: January 6, 2019

**Time:** >90 Minutes (8:30pm to 10pm)

**Today's Progress:** Played around with twitteR package on CRAN. Used instructions from [here](https://towardsdatascience.com/access-data-from-twitter-api-using-r-and-or-python-b8ac342d3efe) to get started

**Thoughts:** Frustrating day. I started out by just experimenting with the twitteR package and ultimately pulled all off Lin Manuel Miranda's "Gmorning" and "Gnight" tweets, however the function seems to only pull the truncated version of tweets when they are over 140 characters. I spent a lot of time trying to find a solution, but up until this point I've come up short. Other options would be to switch over to the rtweet package, or to just pull the API myself. I sort of like the latter, as I don't have much experience with APIs. 

**Link to work:** [Twitter API Functions](https://github.com/EFastner/twitter_api)

### Day 7: January 7, 2019

**Time:** >90 Minutes (7:30pm to 9:00pm)

**Today's Progress:** Experimented more with RPostgreSQL, created some new tables, and set up some functions to make basic queries. These should come in handy for pulling data across seasons. One of the issues that I used to have was reading multiple seasons into memory from multiple .csv files and then filtering out what I needed. Now I should be able to just query the filtered data straight from the SQL tables as needed.

**Thoughts:** I'm really excited about where this is going. I added in the tables with draft years, which means I can hopefully use this code to query data by game for each player

**Link to work:** [Basic RPostgreSQL Queries](https://github.com/EFastner/RPostgreSQL_Functions/blob/master/basic_queries.r)

### Day 8: January 8, 2019

**Time:** 60 Minutes (5:15pm to 6:15pm)

**Today's Progress:** Revisited some of the game summary functions that I created back when I first started with the Tidyverse. Lot's to clean up

**Thoughts:** Some of the sins of my past came back to haunt me. I spent a lot of time just jumping from function to function trying to figure out what format data frames needed to be in, what I was missing, etc. Lots of opportunity to clean this up in the future, may implement some unit testing? 

**Link to work:** [PBP Functions](https://github.com/EFastner/PbP_Analysis/tree/master/PBP_Functions)

### Day 9: January 9, 2019

**Time:** 60 Minutes (10:45pm to 11:45pm)

**Today's Progress:** Started to learn how to design a Shiny App using this [tutorial](https://deanattali.com/blog/building-shiny-apps-tutorial/). Got through the first 8 sections and now need to implement some server logic

**Thoughts:** This was a whole lot of fun! Shiny apps seem a lot easier than I thought, I think it may be possible to implement this with the lock line analysis that I did earlier than I thought 

**Link to work:** [Shiny App Tutorial](https://github.com/EFastner/shiny_app_tutorial)

### Day 10: January 10, 2019

**Time:** 60 Minutes (10:40pm to 11:40pm)

**Today's Progress:** Continued the tutorial from yesterday. Added interactive plots to go with the ui setup 

**Thoughts:** This was a little more challenging, especially because it's clearly been awhile since I've used ggplot2. I'll need a refresher before long

**Link to work:** [Shiny App Tutorial](https://github.com/EFastner/shiny_app_tutorial)

### Day 11: January 11, 2019

**Time:** 60 Minutes (8:15pm to 9:15pm)

**Today's Progress:** Finished the Shiny app tutorial and published the app to shinyapps.io

**Thoughts:** There is a lot ot unpack in Shiny. I think next steps should be just to start building a lock line app and see what happens

**Link to work:** [Final Shiny App](https://efastner.shinyapps.io/Shiny_App_Tutorial/)

### Day 12: January 12, 2019

**Time:** 120 Minutes (8:30am to 9:30am and 5:00pm to 6:00pm)

**Today's Progress:** Started to build a Shiny app for the Lock Line Analysis that I had completed previously

**Thoughts:** Shiny apps are still a little confusing....I'll have to do some work here to really understand it.

**Link to work:** [Lock Line Shiny App](https://github.com/EFastner/Lock_Line_Analysis/tree/master/shiny_app)

### Day 13: January 13, 2019

**Time:** 75 Minutes (11:00am to 12:45am)

**Today's Progress:** Fixed an issue with the date format showing up incorrectly in my lock line Shiny App, added an export button, published to shinyapps.io

**Thoughts:** Shiny is confusing, but it's certainly fun to use! Hopefully as I keep using it I'll get more comfortable with the concepts that it utilizes

**Link to work:** [Lock Line Shiny App on shinyapps.io](https://efastner.shinyapps.io/lock_line_analysis/)

### Day 14: January 14, 2019

**Time:** 90 Minutes (9:00pm to 10:30pm)

**Today's Progress:** Cleaned up the plot for the lock line Shiny app, added an overview and definitions to the sidebar, changed data table to use the DT package

**Thoughts:** I'm getting more comfortable with Shiny, but I still feel like I have a long way to go!

**Link to work:** [Lock Line Shiny App on shinyapps.io](https://efastner.shinyapps.io/lock_line_analysis/)

### Day 15: January 15, 2019

**Time:** 90 Minutes (10:30pm to 12:00am)

**Today's Progress:** Started to build a list of players to use for my prospect ceiling project using RPostgreSQL

**Thoughts:** There was a rough moment when I accidentally used "rm" instead of "mv" on the command line and almost lost everything, but I got it back! It's clear that there is an issue with my GameScores in my SQL database. I'll need to investigate tomorrow.

**Link to work:** [Start of code to create skater list](https://github.com/EFastner/Mentorship_Project/blob/master/data_analysis/skater_list.r)

### Day 16: January 16, 2019

**Time:** 60 Minutes (2:30pm to 3:30pm)

**Today's Progress:** Played around with some basic functions in rtweet. Laid building blocks for the gmorning_gnight functions

**Thoughts:** This is way easier than twitteR!

**Link to work:** [Basic rtweet functions](https://github.com/EFastner/twitter_api/blob/master/rtweet_basics.r)

### Day 17: January 17, 2019

**Time:** 60 Minutes (6:00pm to 6:30pm and 9:30pm to 10:00pm)

**Today's Progress:** Split out gmorning_gnight functions, found a way to identify which tweet could possibly be the right tweet on a day where the keyword is used multiple times

**Thoughts:** I'm not sure how I can better identify the right tweets, but there is still something to be desired on here

**Link to work:** [gmorning_gnight](https://github.com/EFastner/twitter_api/blob/master/Gmorning_Gnight.r)

### MISSED - Day 18: January 18, 2019

**Time:**

**Today's Progress:**

**Thoughts:**

**Link to work:**

### Day 19: January 19, 2019

**Time:** 90 Minutes (5:15pm to 6:45pm)

**Today's Progress:** Updated my RPostgreSQL functions to make them more functional. Added getPass functionality to the connection function, made the create table function work with variables for the table name and the column names, created a function that creates the string for creating row names for large databases. Setting the stage to create a gmorning_gnight database tomorrow

**Thoughts:** I'm getting better at this, but I still make some easy SQL mistakes. It's been nice to challenge myself on this. 

**Link to work:** [RPostgreSQL Functions](https://github.com/EFastner/RPostgreSQL_Functions)

### Day 20: January 20, 2019

**Time:** 90 Minutes (8:00pm to 9:30pm)

**Today's Progress:** Finalized the gmorning and gnight tables in Postgres, began building a script for updating these on a regular basis. Also input all of the current Hamilthoughts into a table, not sure why yet

**Thoughts:** I'm excited to start playing with the data now instead of just importing it

**Link to work:** [RPostgreSQL Functions](https://github.com/EFastner/RPostgreSQL_Functions)

### Day 21: January 21, 2019

**Time:** 60 Minutes (11:00pm to 12:00am)

**Today's Progress:** Created script for daily updating. Hoping to load onto the Raspeberry Pi tomorrow and create a Cron job to update each day

**Thoughts:** Hopefully building a Cron Job will build a good foundation for updating this in the future

**Link to work:** [Daily update script](https://github.com/EFastner/twitter_api/blob/master/gmorning_gnight/get_daily_tweets.r)

### Day 22: January 22, 2019

**Time:** 60 Minutes (11:00pm to 12:00am)

**Today's Progress:** Updated daily tweet script to correct the created_at values to central time zone, moved to Raspberry Pi, installed dependencies, and TRIED to run a cron job, but was missing RPostgreSQL. I also updated the create_at values in my SQL database to also coincide in central time zone

**Thoughts:** Well, I'm close. Learned a lot, but unfortunately didn't quite work out. At least I got the SQL values figured out so I should be ready for the final cron job tomorrow. 

**Link to work:** [Daily update script](https://github.com/EFastner/twitter_api/blob/master/gmorning_gnight/get_daily_tweets.r)

### Day 23: January 23, 2019

**Time:** 60 Minutes (7:30pm to 8:30pm)

**Today's Progress:** Finally got all dependencies installed on the Raspberry Pi and successfully ran the script to update my SQL tables. Will run at 5am, will hopefully work ok

**Thoughts:** This was just a good reminder to understand how concepts work together rather than just trying to put the right characters together to complete a task. Everything looks ok now, we'll see how well I did tomorrow morning

**Link to work:** [Daily update script](https://github.com/EFastner/twitter_api/blob/master/gmorning_gnight/get_daily_tweets.r)